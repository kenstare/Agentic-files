{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "457a5d16",
   "metadata": {},
   "source": [
    "Retrieval-Augmented Agent Project\n",
    "1. System Overview\n",
    "This project implements an agentic Retrieval-Augmented Generation (RAG) system focused on the domain of industrial chemical safety and process safety management. The goal of the system is to provide accurate, context-aware responses to user queries by intelligently deciding when to rely on general language model knowledge and when to retrieve authoritative information from a specialized document corpus.\n",
    "\n",
    "The system is built using LangGraph, with an agent node responsible for reasoning and decision-making, and a tool node connected to a document retrieval function backed by a Chroma vector store. Domain-specific documents, including safety guidelines, risk assessment procedures, and emergency response materials, are embedded and stored to enable semantic search.\n",
    "\n",
    "A conditional control flow allows the agent to determine whether document retrieval is necessary based on the nature of the user query. General or conversational questions are answered directly, while technical or safety-critical questions trigger retrieval before response generation. Conversation memory is integrated to support multi-turn interactions within a session, enabling coherent and context-aware dialogue. The system supports both single-query execution and an interactive chat interface for user interaction.\n",
    "\n",
    "Note : Remember to do edit this later before sumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "829fce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from IPython.display import Image, display, Markdown, HTML, Latex\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "from typing import Literal\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05eac2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded\n"
     ]
    }
   ],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in your .env file.\")\n",
    "\n",
    "print(\"API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e94013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5496b3e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m                 pages.append(page)\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pages\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m documents = \u001b[38;5;28;01mawait\u001b[39;00m load_all_pdfs(file_path)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m pages from PDFs\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mload_all_pdfs\u001b[39m\u001b[34m(pdf_dir)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_all_pdfs\u001b[39m(pdf_dir: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      8\u001b[39m     pages = []\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filename.lower().endswith(\u001b[33m\"\u001b[39m\u001b[33m.pdf\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     12\u001b[39m             file_path = os.path.join(pdf_dir, filename)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: './documents'"
     ]
    }
   ],
   "source": [
    "# Prevent messy PDF logs\n",
    "logging.getLogger(\"pypdf\").setLevel(logging.ERROR)\n",
    "\n",
    "# file path\n",
    "file_path = \"./documents\"\n",
    "\n",
    "async def load_all_pdfs(pdf_dir: str):\n",
    "    pages = []\n",
    "\n",
    "    for filename in os.listdir(pdf_dir):\n",
    "        if filename.lower().endswith(\".pdf\"):\n",
    "            file_path = os.path.join(pdf_dir, filename)\n",
    "            loader = PyMuPDFLoader(file_path)\n",
    "\n",
    "            async for page in loader.alazy_load():\n",
    "                page.metadata[\"source\"] = filename\n",
    "                pages.append(page)\n",
    "\n",
    "    return pages\n",
    "\n",
    "documents = await load_all_pdfs(file_path)\n",
    "print(f\"Loaded {len(documents)} pages from PDFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc96ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_chunk_by_sections(documents, chunk_size=1000, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    Smart chunking for better retrieval:\n",
    "    - Skips blank pages\n",
    "    - Chunks each document independently\n",
    "    - Prevents bias toward any single document\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Original documents: {len(documents)}\")\n",
    "\n",
    "    # Intelligent splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\n",
    "            \"\\n\\n\",\n",
    "            \"\\n\",\n",
    "            \". \",\n",
    "            \" \",\n",
    "            \"\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    all_chunks = []\n",
    "\n",
    "    for idx, doc in enumerate(documents):\n",
    "        content = doc.page_content.strip()\n",
    "\n",
    "        if not content:\n",
    "            continue  # Skip blank pages\n",
    "\n",
    "        # Preserve document identity without bias\n",
    "        single_doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={**doc.metadata, \"doc_index\": idx}\n",
    "        )\n",
    "\n",
    "        doc_splits = text_splitter.split_documents([single_doc])\n",
    "        all_chunks.extend(doc_splits)\n",
    "\n",
    "        # print(f\"‚úì Document {idx + 1}: {len(doc_splits)} chunks\")\n",
    "\n",
    "    print(f\"\\nTotal chunks created: {len(all_chunks)}\")\n",
    "    return all_chunks\n",
    "\n",
    "\n",
    "def view_chunks_with_context(chunks, num_chunks_to_show=10):\n",
    "    \"\"\"\n",
    "    Display chunk previews (for sanity checking only)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"CHUNK PREVIEW\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for i, chunk in enumerate(chunks[:num_chunks_to_show]):\n",
    "        print(f\"\\n--- CHUNK {i + 1} ---\")\n",
    "        print(f\"Length: {len(chunk.page_content)} characters\")\n",
    "        print(\"Preview (first 300 chars):\")\n",
    "        print(chunk.page_content[:300])\n",
    "        print(\"...\")\n",
    "        if i < num_chunks_to_show - 1:\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Chunk the documents (ALL documents treated equally)\n",
    "    chunks_1000 = smart_chunk_by_sections(\n",
    "        documents,\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "\n",
    "    # # print(f\"\\n‚úì Total chunks: {len(chunks_1000)}\")\n",
    "\n",
    "    # Chunk statistics\n",
    "    chunk_sizes = [len(c.page_content) for c in chunks_1000]\n",
    "    print(\"\\nChunk size statistics:\")\n",
    "    print(f\"  Min: {min(chunk_sizes)} chars\")\n",
    "    print(f\"  Max: {max(chunk_sizes)} chars\")\n",
    "    print(f\"  Avg: {sum(chunk_sizes) / len(chunk_sizes):.0f} chars\")\n",
    "\n",
    "    # Optional preview (debug only)\n",
    "    view_chunks_with_context(chunks_1000, num_chunks_to_show=5)\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"Chunks are ready for unbiased RAG retrieval across all documents.\")\n",
    "    print(f\"{'=' * 80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83befdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings (using OpenAI)\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(\"Embeddings model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_path = \"./chroma_db\"\n",
    "collection_name = \"becoming_a_quant\"\n",
    "\n",
    "# Check if Chroma DB already exists\n",
    "db_exists = os.path.exists(chroma_path) and len(os.listdir(chroma_path)) > 0\n",
    "\n",
    "if db_exists:\n",
    "    print(\"Existing Chroma DB found. Loading...\")\n",
    "    \n",
    "    vectorstore = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        persist_directory=chroma_path,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"No existing Chroma DB found. Creating new one...\")\n",
    "    \n",
    "    vectorstore = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        persist_directory=chroma_path,\n",
    "        embedding_function=embeddings\n",
    "    ) \n",
    "    vectorstore.add_documents(documents=chunks_1000)\n",
    "\n",
    "\n",
    "    print(f\"Vector store created with {len(chunks_1000)} chunks\")\n",
    "    print(f\"   Persisted to: {chroma_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dbc7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"What is Algorithmic Trading?\"\n",
    "test_results = vectorstore.similarity_search(test_query, k=2)\n",
    "\n",
    "print(f\"Query: {test_query}\")\n",
    "print(\"\\nRetrieved Chunks:\\n\")\n",
    "\n",
    "for i, doc in enumerate(test_results, 1):\n",
    "    print(f\"Result {i}\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"Content:\\n{doc.page_content[:600]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaee5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"Who is Peter Carr?\"\n",
    "test_results = vectorstore.similarity_search(test_query, k=2)\n",
    "\n",
    "print(f\"Query: {test_query}\")\n",
    "print(\"\\nRetrieved Chunks:\\n\")\n",
    "\n",
    "for i, doc in enumerate(test_results, 1):\n",
    "    print(f\"Result {i}\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"Content:\\n{doc.page_content[:600]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_documents(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for relevant documents in the knowledge base.\n",
    "    \n",
    "    Use this tool when you need information from the document collection\n",
    "    to answer the user's question. Do NOT use this for:\n",
    "    - General knowledge questions\n",
    "    - Greetings or small talk\n",
    "    - Simple calculations\n",
    "    \n",
    "    Args:\n",
    "        query: The search query describing what information is needed\n",
    "        \n",
    "    Returns:\n",
    "        Relevant document excerpts that can help answer the question\n",
    "    \"\"\"\n",
    "    # Use MMR (Maximum Marginal Relevance) for diverse results\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": 5, \"fetch_k\": 10}\n",
    "    )\n",
    "    \n",
    "    # Retrieve documents\n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant documents found.\"\n",
    "    \n",
    "    # Format results\n",
    "    formatted = \"\\n\\n---\\n\\n\".join(\n",
    "        f\"Document {i+1}:\\n\"\n",
    "        f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\"\n",
    "        f\"Page: {doc.metadata.get('page', 'N/A')}\\n\"\n",
    "        f\"Content:\\n{doc.page_content}\"\n",
    "        for i, doc in enumerate(results)\n",
    "    )\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "print(\"Retrieval tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"What is Algorithmic Trading?\"\n",
    "\n",
    "# Test tool directly\n",
    "test_result = retrieve_documents.invoke({\"query\": \"Explain the Advantages and Disadvantages of Algorithmic Trading.\"})\n",
    "print(f\"Tool result (first 500 chars):\\n{test_result[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39fffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessage(content=\"\"\"\n",
    "You are an assistant specialized in quantitative finance, derivatives pricing, and risk management.\n",
    "Your knowledge source is a collection of quantitative finance documents and financial modeling resources.\n",
    "\n",
    "DOMAIN RESTRICTION:\n",
    "Only answer questions related to:\n",
    "- Quantitative finance and derivatives pricing\n",
    "- Risk management and portfolio theory\n",
    "- Financial modeling and numerical methods (Monte Carlo, finite differences, binomial trees)\n",
    "- Options pricing, Greeks, and hedging strategies\n",
    "- Fixed income instruments and interest rate models\n",
    "- Credit derivatives and structured products\n",
    "- Volatility modeling and stochastic processes\n",
    "- Mathematical finance fundamentals (It√¥'s lemma, Brownian motion, etc.)\n",
    "\n",
    "If a question is outside this domain AND no relevant information is found in the retrieved documents,\n",
    "politely respond that it is outside your scope.\n",
    "\n",
    "If relevant information IS found in the retrieved documents,\n",
    "answer the question strictly using the documents, even if the topic is outside quantitative finance.\n",
    "\n",
    "RETRIEVAL DECISION RULES:\n",
    "\n",
    "DO NOT retrieve for:\n",
    "- Greetings or small talk (\"Hello\", \"Thank you\")\n",
    "- Questions about your capabilities\n",
    "- Very general conceptual questions that do NOT depend on the documents\n",
    "(e.g., \"What is finance?\")\n",
    "\n",
    "DO retrieve for:\n",
    "- Questions requiring procedural steps, formulas, or detailed explanations\n",
    "- Questions that depend on document-specific information (models, case studies, examples)\n",
    "- Technical questions about pricing, hedging, or risk management\n",
    "- Any request where citing documents improves accuracy\n",
    "- When in doubt about whether a concept is document-backed, prefer retrieval.\n",
    "\n",
    "\n",
    "When documents are retrieved:\n",
    "- Use them as the primary source of truth\n",
    "- Cite the document source, chapter, or page when possible\n",
    "- Include relevant formulas, equations, or technical details from the documents\n",
    "- If the documents do not contain the answer, say so explicitly\n",
    "\n",
    "Never fabricate pricing models, formulas, or quantitative methodologies.\n",
    "Always distinguish between classical theory and real-world practice.\n",
    "                              \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aa3076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind tool to LLM\n",
    "tools = [retrieve_documents]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def assistant(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    Assistant node - decides whether to retrieve or answer directly.\n",
    "    \"\"\"\n",
    "    # messages = [system_prompt] + state[\"messages\"]\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Inject system prompt only once\n",
    "    if not messages or messages[0].type != \"system\":\n",
    "        messages = [system_prompt] + messages\n",
    "        \n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Decide whether to call tools or finish.\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe8eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"__end__\": END}\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "agent = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebb9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the agentic RAG graph\n",
    "try:\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"Graph: START ‚Üí assistant ‚Üí [if tool_call] ‚Üí tools ‚Üí assistant ‚Üí END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9545507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_latex_for_display(text):\n",
    "    \"\"\"\n",
    "    Converts LaTeX in text to proper Markdown format for Jupyter rendering\n",
    "    Handles both inline ($...$) and display ($$...$$) math\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return text\n",
    "\n",
    "    text = re.sub(r'\\\\\\(', '$', text)\n",
    "    text = re.sub(r'\\\\\\)', '$', text)\n",
    "    text = re.sub(r'\\\\\\[', '$$\\n', text)\n",
    "    text = re.sub(r'\\\\\\]', '\\n$$', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def query_agent(user_input: str, thread_id: str = \"default_session\"):\n",
    "    \"\"\"\n",
    "    Improved query function with clear, well-formatted output.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üë§ User: {user_input}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "\n",
    "    used_retrieval = False\n",
    "    final_answer = None\n",
    "\n",
    "    for message in result[\"messages\"]:\n",
    "        if isinstance(message, AIMessage):\n",
    "            if message.tool_calls:\n",
    "                used_retrieval = True\n",
    "                print(\"üîç Agent: [Calling retrieval tool...]\")\n",
    "            if message.content and not message.tool_calls:\n",
    "                final_answer = message.content\n",
    "\n",
    "    if final_answer:\n",
    "        # Convert LaTeX\n",
    "        final_answer = convert_latex_for_display(final_answer)\n",
    "\n",
    "        # Render as Markdown (fixes formulas)\n",
    "        display(Markdown(f\"### ü§ñ Agent Response\\n\\n{final_answer}\"))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No response generated after retrieval!\")\n",
    "\n",
    "    print(f\"\\nüìä Decision: {'USED RETRIEVAL' if used_retrieval else 'ANSWERED DIRECTLY'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_agent(\"Explain the Discrete Time Models in Quantitative Finance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d71ee",
   "metadata": {},
   "source": [
    "ü§ñ Agent Response\n",
    "Discrete time models in quantitative finance are frameworks where asset prices and time progress in finite increments. Here are the key features and concepts associated with these models:\n",
    "\n",
    "Definition: Discrete time models allow for changes in asset prices and time to occur only at specific intervals, such as daily, weekly, or monthly. This contrasts with continuous models, where changes can happen at any moment.\n",
    "\n",
    "Mathematical Framework: In discrete models, the evolution of asset prices is typically described using difference equations. For example, if \n",
    " represents the asset price at time \n",
    ", a simple difference equation might be: $$\n",
    "\n",
    "S_{t+1} = S_t \\cdot u \\quad \\text{(up move)}\n",
    "\n",
    "\n",
    "S_{t+1} = S_t \\cdot d \\quad \\text{(down move)}\n",
    "\n",
    "$$ where \n",
    " and \n",
    " are the factors by which the price increases or decreases.\n",
    "\n",
    "Binomial Model: A well-known example of a discrete time model is the binomial model for option pricing. In this model, the price of an asset can move to one of two possible values (up or down) at each time step, creating a tree structure that allows for the calculation of option prices based on the possible future paths of the underlying asset.\n",
    "\n",
    "Applications: Discrete time models are widely used in various financial applications, including option pricing, risk management, and portfolio optimization. They are particularly useful for numerical methods such as Monte Carlo simulations and finite difference methods, which often require discretization of continuous processes.\n",
    "\n",
    "Comparison with Continuous Models: While continuous models, such as those based on stochastic calculus (e.g., Black-Scholes), can be mathematically elegant, discrete models are often more practical for computational purposes. In practice, continuous models are typically approximated using discrete methods for numerical analysis.\n",
    "\n",
    "In summary, discrete time models are essential tools in quantitative finance, providing a structured approach to modeling asset price movements and facilitating the pricing of derivatives and risk management strategies.\n",
    "\n",
    "üìä Decision: USED RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f203b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_chat_with_mathjax(thread_id: str):\n",
    "    \"\"\"\n",
    "    Interactive chat with explicit MathJax rendering\n",
    "    Better for complex mathematical expressions\n",
    "    \"\"\"\n",
    "    print(\"ü§ñ Interactive Chat (Notebook Mode)\")\n",
    "    print(\"Type 'exit' to quit\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"üë§ You: \").strip()\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            display(Markdown(\"üëã **Goodbye!**\"))\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        display(Markdown(f\"**üë§ You:** {user_input}\"))\n",
    "        \n",
    "        thinking_display = display(\n",
    "            Markdown(\"ü§ñ *Agent is thinking‚Ä¶*\"),\n",
    "            display_id=True\n",
    "        )\n",
    "        \n",
    "        result = agent.invoke(\n",
    "            {\"messages\": [HumanMessage(content=user_input)]},\n",
    "            config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "        )\n",
    "        \n",
    "        used_retrieval = False\n",
    "        final_answer = None\n",
    "        \n",
    "        for msg in result[\"messages\"]:\n",
    "            if isinstance(msg, AIMessage):\n",
    "                if msg.tool_calls:\n",
    "                    used_retrieval = True\n",
    "                if msg.content and not msg.tool_calls:\n",
    "                    final_answer = msg.content\n",
    "        \n",
    "        decision = \"USED RETRIEVAL\" if used_retrieval else \"ANSWERED DIRECTLY\"\n",
    "        \n",
    "        response_html = f\"\"\"\n",
    "        <div style=\"font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; line-height: 1.6;\">\n",
    "            <h3 style=\"color: #e0e0e0;\">ü§ñ Agent Response</h3>\n",
    "            <div style=\"\n",
    "                background-color: #121212;\n",
    "                color: #ffffff;\n",
    "                padding: 15px;\n",
    "                border-left: 4px solid #7c4dff;\n",
    "                margin: 10px 0;\n",
    "                border-radius: 6px;\n",
    "            \">\n",
    "                {final_answer}\n",
    "            </div>\n",
    "            <p style=\"margin-top: 20px; color: #b0b0b0; font-size: 14px;\">\n",
    "                <strong>üìä Decision:</strong>\n",
    "                <span style=\"background-color: #1e1e1e; padding: 3px 8px; border-radius: 4px;\">\n",
    "                    {decision}\n",
    "                </span>\n",
    "            </p>\n",
    "        </div>\n",
    "\n",
    "        <script src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"></script>\n",
    "        <script id=\"MathJax-script\" async\n",
    "            src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "        <script>\n",
    "            MathJax.typesetPromise().catch(err => console.log(err));\n",
    "        </script>\n",
    "        \"\"\"\n",
    "        \n",
    "        thinking_display.update(HTML(response_html))\n",
    "\n",
    "def format_points_for_html(text):\n",
    "    \"\"\"\n",
    "    Ensures numbered points appear on separate lines inside HTML blocks\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return text\n",
    "\n",
    "    # Force line breaks before numbered points\n",
    "    text = re.sub(r'\\n(\\d+\\.)', r'<br><br>\\1', text)\n",
    "\n",
    "    # Convert bullet dashes into line breaks\n",
    "    text = re.sub(r'\\n-\\s+', r'<br>‚Äì ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac82d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_chat_with_mathjax(\"session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff154f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_chat_with_mathjax(\"session-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e8a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agenvenv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
