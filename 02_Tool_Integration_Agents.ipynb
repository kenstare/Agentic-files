{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 2: Tool Integration for Agents\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand what tools are and why agents need them\n",
    "- Create tools using the `@tool` decorator\n",
    "- Bind tools to LLMs for function calling\n",
    "- Implement conditional routing based on tool calls\n",
    "- Build an agent that decides which tools to use\n",
    "\n",
    "**Prerequisites:** Topic 1 (LangGraph Basics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Why Do Agents Need Tools?\n",
    "\n",
    "### The Problem: LLMs Can't Do Everything\n",
    "\n",
    "LLMs are great at:\n",
    "- ‚úÖ Understanding language\n",
    "- ‚úÖ Generating text\n",
    "- ‚úÖ Reasoning about information\n",
    "\n",
    "But they **can't**:\n",
    "- ‚ùå Search the web in real-time\n",
    "- ‚ùå Perform precise calculations\n",
    "- ‚ùå Access databases or files\n",
    "- ‚ùå Call APIs\n",
    "- ‚ùå Execute code\n",
    "\n",
    "### The Solution: Tools!\n",
    "\n",
    "**Tools** are functions that agents can call to perform actions:\n",
    "\n",
    "```\n",
    "User: \"What's 12345 * 67890?\"\n",
    "\n",
    "Agent thinks: \"I need to calculate this precisely\"\n",
    "         ‚Üì\n",
    "Agent calls: calculator_tool(\"12345 * 67890\")\n",
    "         ‚Üì\n",
    "Tool returns: \"838102050\"\n",
    "         ‚Üì\n",
    "Agent responds: \"The answer is 838,102,050\"\n",
    "```\n",
    "\n",
    "This is the foundation of **agentic behavior** - agents that can DO things!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ü§î Reflection Question:** \n",
    "How is this different from just calling functions in your code? The key is that the **agent decides** when to call the tool - you don't hardcode it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q langgraph langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key loaded\n"
     ]
    }
   ],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in your .env file.\")\n",
    "\n",
    "print(\"‚úÖ API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,  # Lower temperature for more precise tool usage\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Creating Your First Tool\n",
    "\n",
    "Let's start with a simple calculator tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The @tool Decorator\n",
    "\n",
    "The `@tool` decorator converts a Python function into a tool that LLMs can call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Calculator tool created\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Evaluate a mathematical expression and return the result.\n",
    "    Use this tool when you need to perform calculations.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression like \"2 + 2\" or \"15 * 37\"\n",
    "        \n",
    "    Returns:\n",
    "        The calculated result as a string\n",
    "        \n",
    "    Examples:\n",
    "        - \"2 + 2\" returns \"4\"\n",
    "        - \"100 / 5\" returns \"20.0\"\n",
    "        - \"2 ** 10\" returns \"1024\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Evaluate the expression safely\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Calculator tool created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Key Components of a Good Tool:**\n",
    "\n",
    "1. **Clear docstring** - LLM reads this to understand when to use the tool!\n",
    "2. **Type hints** - Helps LLM know what arguments to provide\n",
    "3. **Examples** - Shows LLM how to use the tool\n",
    "4. **Error handling** - Gracefully handle failures\n",
    "5. **Return string** - LLMs work best with string outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Tool Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 * 456 = 56088\n",
      "2^10 = 1024\n"
     ]
    }
   ],
   "source": [
    "# Test the calculator tool\n",
    "result = calculator.invoke({\"expression\": \"123 * 456\"})\n",
    "print(f\"123 * 456 = {result}\")\n",
    "\n",
    "result2 = calculator.invoke(\"2 ** 10\")\n",
    "print(f\"2^10 = {result2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Creating a Second Tool\n",
    "\n",
    "Agents are more useful with multiple tools! Let's add a string manipulation tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text analyzer tool created\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def text_analyzer(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze text and return statistics about it.\n",
    "    Use this tool when you need to analyze or count things in text.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Statistics about the text (characters, words, sentences)\n",
    "        \n",
    "    Examples:\n",
    "        - \"Hello world\" returns character count, word count, etc.\n",
    "    \"\"\"\n",
    "    char_count = len(text)\n",
    "    word_count = len(text.split())\n",
    "    sentence_count = text.count('.') + text.count('!') + text.count('?')\n",
    "    \n",
    "    return f\"\"\"Text Analysis:\n",
    "- Characters: {char_count}\n",
    "- Words: {word_count}\n",
    "- Sentences: {sentence_count}\n",
    "- First 50 chars: {text[:50]}...\"\"\"\n",
    "\n",
    "print(\"‚úÖ Text analyzer tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Analysis:\n",
      "- Characters: 41\n",
      "- Words: 9\n",
      "- Sentences: 3\n",
      "- First 50 chars: Hello! This is a test. How are you today?...\n"
     ]
    }
   ],
   "source": [
    "# Test the text analyzer\n",
    "test_text = \"Hello! This is a test. How are you today?\"\n",
    "result = text_analyzer.invoke({\"text\": test_text})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Binding Tools to the LLM\n",
    "\n",
    "Now we need to tell the LLM about our tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM bound to 2 tools\n",
      "   Tools: ['calculator', 'text_analyzer']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of tools\n",
    "tools = [calculator, text_analyzer]\n",
    "\n",
    "# Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(f\"‚úÖ LLM bound to {len(tools)} tools\")\n",
    "print(f\"   Tools: {[tool.name for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What `bind_tools` does:**\n",
    "1. Sends tool descriptions to the LLM\n",
    "2. LLM can now \"see\" what tools are available\n",
    "3. LLM will decide when to call tools based on user queries\n",
    "\n",
    "This uses **OpenAI's function calling** feature - the LLM returns structured tool calls!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: LLM Decision Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "\n",
      "Content: \n",
      "\n",
      "Tool calls: [{'name': 'calculator', 'args': {'expression': '234 * 567'}, 'id': 'call_p1H2cNzFbvT53W0eakiJkRCU', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# Test: Does LLM decide to call calculator?\n",
    "response = llm_with_tools.invoke([HumanMessage(content=\"What is 234 * 567?\")])\n",
    "\n",
    "print(f\"Response type: {type(response)}\")\n",
    "print(f\"\\nContent: {response.content}\")\n",
    "print(f\"\\nTool calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ Key Observation:** \n",
    "The LLM didn't return a direct answer - it returned a **tool call**! This is the agent saying \"I need to use the calculator tool.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "Tool calls: []\n"
     ]
    }
   ],
   "source": [
    "# Test: Does LLM decide NOT to call tools for simple queries?\n",
    "response2 = llm_with_tools.invoke([HumanMessage(content=\"Hello! How are you?\")])\n",
    "\n",
    "print(f\"Content: {response2.content}\")\n",
    "print(f\"Tool calls: {response2.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Smart Decision:** The LLM knows it doesn't need tools for greetings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Building the Agent Graph\n",
    "\n",
    "Now let's build a complete agent that can use these tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the Assistant Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Assistant node defined\n"
     ]
    }
   ],
   "source": [
    "# System prompt that encourages tool usage\n",
    "sys_msg = SystemMessage(content=\"\"\"You are a helpful assistant with access to tools.\n",
    "\n",
    "When asked to perform calculations, use the calculator tool.\n",
    "When asked to analyze text, use the text_analyzer tool.\n",
    "\n",
    "Only use tools when necessary - for simple questions, answer directly.\"\"\")\n",
    "\n",
    "def assistant(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    Assistant node - decides whether to use tools or answer directly.\n",
    "    \"\"\"\n",
    "    messages = [sys_msg] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"‚úÖ Assistant node defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define Conditional Routing\n",
    "\n",
    "This is the **key to agentic behavior** - the graph decides where to go based on whether tools were called!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conditional routing function defined\n"
     ]
    }
   ],
   "source": [
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Decide next step based on last message.\n",
    "    \n",
    "    If LLM called a tool ‚Üí go to 'tools' node\n",
    "    If LLM provided final answer ‚Üí go to END\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # Check if LLM made tool calls\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # No tool calls - we're done\n",
    "    return \"__end__\"\n",
    "\n",
    "print(\"‚úÖ Conditional routing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üîç Understanding the Flow:**\n",
    "\n",
    "```\n",
    "User Query ‚Üí Assistant Node ‚Üí Tool calls?\n",
    "                                  ‚îú‚îÄ YES ‚Üí Tools Node ‚Üí Back to Assistant\n",
    "                                  ‚îî‚îÄ NO  ‚Üí END (return answer)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent graph compiled with tools and memory\n"
     ]
    }
   ],
   "source": [
    "# Create the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))  # ToolNode executes tool calls automatically\n",
    "\n",
    "# Define edges\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"__end__\": END}\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")  # After tools, go back to assistant\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"‚úÖ Agent graph compiled with tools and memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Note on ToolNode:**\n",
    "`ToolNode(tools)` is a LangGraph helper that:\n",
    "1. Reads tool calls from the last message\n",
    "2. Executes the appropriate tool\n",
    "3. Returns results as ToolMessage\n",
    "\n",
    "This saves us from manually implementing tool execution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Visualize the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the agent graph\n",
    "try:\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"Graph structure: START ‚Üí assistant ‚Üí [conditional] ‚Üí tools ‚Üí assistant ‚Üí END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üé® Notice the difference from Topic 1:**\n",
    "- Topic 1: Linear (START ‚Üí assistant ‚Üí END)\n",
    "- Topic 2: Has a **cycle** (tools can loop back to assistant)\n",
    "\n",
    "This is agentic behavior - the agent can use tools multiple times if needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Testing the Tool-Using Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test function ready\n"
     ]
    }
   ],
   "source": [
    "# Helper function\n",
    "def run_agent(user_input: str, thread_id: str = \"test_session\"):\n",
    "    \"\"\"\n",
    "    Run the agent and display the conversation.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üë§ User: {user_input}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    \n",
    "    for message in result[\"messages\"]:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            continue  # Already printed\n",
    "        elif isinstance(message, AIMessage):\n",
    "            if message.tool_calls:\n",
    "                print(f\"ü§ñ Agent: [Calling tool: {message.tool_calls[0]['name']}]\")\n",
    "            else:\n",
    "                print(f\"ü§ñ Agent: {message.content}\")\n",
    "        elif isinstance(message, ToolMessage):\n",
    "            print(f\"üîß Tool Result: {message.content[:100]}...\" if len(message.content) > 100 else f\"üîß Tool Result: {message.content}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\\n\")\n",
    "\n",
    "print(\"‚úÖ Test function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Calculator Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: What is 12345 * 67890?\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 838102050\n",
      "ü§ñ Agent: The result of \\( 12345 \\times 67890 \\) is 838,102,050.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"What is 12345 * 67890?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ Expected Flow:**\n",
    "1. Agent sees it needs to calculate\n",
    "2. Calls calculator tool\n",
    "3. Gets result from tool\n",
    "4. Returns formatted answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Text Analyzer Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: Analyze this text: 'RAG systems combine retrieval with generation. They are very useful!'\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 838102050\n",
      "ü§ñ Agent: The result of \\( 12345 \\times 67890 \\) is 838,102,050.\n",
      "ü§ñ Agent: [Calling tool: text_analyzer]\n",
      "üîß Tool Result: Text Analysis:\n",
      "- Characters: 68\n",
      "- Words: 10\n",
      "- Sentences: 2\n",
      "- First 50 chars: RAG systems combine ret...\n",
      "ü§ñ Agent: Here is the analysis of the text:\n",
      "\n",
      "- **Characters**: 68\n",
      "- **Words**: 10\n",
      "- **Sentences**: 2\n",
      "- **First 50 characters**: \"RAG systems combine retrieval with generation. The...\"\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"Analyze this text: 'RAG systems combine retrieval with generation. They are very useful!'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: No Tool Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: Hello! What can you help me with?\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 838102050\n",
      "ü§ñ Agent: The result of \\( 12345 \\times 67890 \\) is 838,102,050.\n",
      "ü§ñ Agent: [Calling tool: text_analyzer]\n",
      "üîß Tool Result: Text Analysis:\n",
      "- Characters: 68\n",
      "- Words: 10\n",
      "- Sentences: 2\n",
      "- First 50 chars: RAG systems combine ret...\n",
      "ü§ñ Agent: Here is the analysis of the text:\n",
      "\n",
      "- **Characters**: 68\n",
      "- **Words**: 10\n",
      "- **Sentences**: 2\n",
      "- **First 50 characters**: \"RAG systems combine retrieval with generation. The...\"\n",
      "ü§ñ Agent: Hello! I can assist you with a variety of tasks, including:\n",
      "\n",
      "1. **Mathematical Calculations**: I can perform calculations and solve mathematical expressions.\n",
      "2. **Text Analysis**: I can analyze text for statistics such as character count, word count, and sentence count.\n",
      "3. **General Information**: I can provide information on a wide range of topics.\n",
      "\n",
      "Feel free to ask me anything specific you'd like help with!\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"Hello! What can you help me with?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Smart Agent:** Notice it didn't use any tools - it knew a greeting doesn't need tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Wrong Tool Choice?\n",
    "\n",
    "Let's see if the agent chooses the right tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: How many words are in this sentence: 'LangGraph makes building agents easy'?\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 838102050\n",
      "ü§ñ Agent: The result of \\( 12345 \\times 67890 \\) is 838,102,050.\n",
      "ü§ñ Agent: [Calling tool: text_analyzer]\n",
      "üîß Tool Result: Text Analysis:\n",
      "- Characters: 68\n",
      "- Words: 10\n",
      "- Sentences: 2\n",
      "- First 50 chars: RAG systems combine ret...\n",
      "ü§ñ Agent: Here is the analysis of the text:\n",
      "\n",
      "- **Characters**: 68\n",
      "- **Words**: 10\n",
      "- **Sentences**: 2\n",
      "- **First 50 characters**: \"RAG systems combine retrieval with generation. The...\"\n",
      "ü§ñ Agent: Hello! I can assist you with a variety of tasks, including:\n",
      "\n",
      "1. **Mathematical Calculations**: I can perform calculations and solve mathematical expressions.\n",
      "2. **Text Analysis**: I can analyze text for statistics such as character count, word count, and sentence count.\n",
      "3. **General Information**: I can provide information on a wide range of topics.\n",
      "\n",
      "Feel free to ask me anything specific you'd like help with!\n",
      "ü§ñ Agent: [Calling tool: text_analyzer]\n",
      "üîß Tool Result: Text Analysis:\n",
      "- Characters: 36\n",
      "- Words: 5\n",
      "- Sentences: 0\n",
      "- First 50 chars: LangGraph makes building...\n",
      "ü§ñ Agent: The sentence \"LangGraph makes building agents easy\" contains 5 words.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"How many words are in this sentence: 'LangGraph makes building agents easy'?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéØ Expected:** Should use `text_analyzer`, not `calculator`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 5: Conversational Context with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: Calculate 100 * 50\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 5000\n",
      "ü§ñ Agent: The result of \\( 100 \\times 50 \\) is 5000.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First query\n",
    "run_agent(\"Calculate 100 * 50\", thread_id=\"calc_session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë§ User: Now add 1000 to that result\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 5000\n",
      "ü§ñ Agent: The result of \\( 100 \\times 50 \\) is 5000.\n",
      "ü§ñ Agent: [Calling tool: calculator]\n",
      "üîß Tool Result: 6000\n",
      "ü§ñ Agent: Adding 1000 to the previous result gives us 6000.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Follow-up - does it remember?\n",
    "run_agent(\"Now add 1000 to that result\", thread_id=\"calc_session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéâ Amazing:** The agent remembers the previous result AND uses the calculator for the new calculation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Understanding Tool Messages\n",
    "\n",
    "Let's inspect what happens behind the scenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã FULL MESSAGE HISTORY:\n",
      "\n",
      "1. HumanMessage\n",
      "   Content: What is 15 * 25?\n",
      "\n",
      "2. AIMessage\n",
      "   Tool Call: calculator({'expression': '15 * 25'})\n",
      "\n",
      "3. ToolMessage\n",
      "   Content: 375\n",
      "\n",
      "4. AIMessage\n",
      "   Content: 15 * 25 equals 375.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get full message history\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is 15 * 25?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"inspect_session\"}}\n",
    ")\n",
    "\n",
    "print(\"\\nüìã FULL MESSAGE HISTORY:\\n\")\n",
    "for i, msg in enumerate(result[\"messages\"], 1):\n",
    "    print(f\"{i}. {type(msg).__name__}\")\n",
    "    if isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "        print(f\"   Tool Call: {msg.tool_calls[0]['name']}({msg.tool_calls[0]['args']})\")\n",
    "    elif isinstance(msg, ToolMessage):\n",
    "        print(f\"   Content: {msg.content}\")\n",
    "    elif hasattr(msg, 'content'):\n",
    "        print(f\"   Content: {msg.content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üîç Message Flow:**\n",
    "1. `HumanMessage` - User's query\n",
    "2. `AIMessage` (with tool_calls) - Agent decides to call calculator\n",
    "3. `ToolMessage` - Result from calculator tool\n",
    "4. `AIMessage` (no tool_calls) - Agent's final answer\n",
    "\n",
    "This is the standard **ReAct** pattern: Reason ‚Üí Act ‚Üí Observe ‚Üí Respond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: Adding a Third Tool (Bonus)\n",
    "\n",
    "Let's add one more tool to show how flexible this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent v2 created with 3 tools\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def coin_flip() -> str:\n",
    "    \"\"\"\n",
    "    Flip a coin and return heads or tails.\n",
    "    \n",
    "    Use this when the user wants a random choice or coin flip.\n",
    "    \n",
    "    Returns:\n",
    "        Either \"Heads\" or \"Tails\"\n",
    "    \"\"\"\n",
    "    import random\n",
    "    return random.choice([\"Heads\", \"Tails\"])\n",
    "\n",
    "# Rebuild agent with 3 tools\n",
    "tools_v2 = [calculator, text_analyzer, coin_flip]\n",
    "llm_with_tools_v2 = llm.bind_tools(tools_v2)\n",
    "\n",
    "def assistant_v2(state: MessagesState) -> dict:\n",
    "    messages = [sys_msg] + state[\"messages\"]\n",
    "    response = llm_with_tools_v2.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "builder_v2 = StateGraph(MessagesState)\n",
    "builder_v2.add_node(\"assistant\", assistant_v2)\n",
    "builder_v2.add_node(\"tools\", ToolNode(tools_v2))\n",
    "builder_v2.add_edge(START, \"assistant\")\n",
    "builder_v2.add_conditional_edges(\"assistant\", should_continue, {\"tools\": \"tools\", \"__end__\": END})\n",
    "builder_v2.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "agent_v2 = builder_v2.compile(checkpointer=MemorySaver())\n",
    "\n",
    "print(\"‚úÖ Agent v2 created with 3 tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: The coin flip result is Heads!\n"
     ]
    }
   ],
   "source": [
    "# Test coin flip\n",
    "result = agent_v2.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Flip a coin for me!\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"coin_session\"}}\n",
    ")\n",
    "\n",
    "for msg in result[\"messages\"]:\n",
    "    if isinstance(msg, AIMessage) and not msg.tool_calls:\n",
    "        print(f\"ü§ñ Agent: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ú® Scalability:** You can add as many tools as you need - the agent will learn to use them all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 10: Preparing for Topic 3 (Agentic RAG)\n",
    "\n",
    "In Topic 3, we'll create a **retrieval tool** that searches a vector store. It will work exactly like these tools:\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def retrieve_documents(query: str) -> str:\n",
    "    \"\"\"Retrieve relevant documents from vector store.\"\"\"\n",
    "    docs = vectorstore.similarity_search(query)\n",
    "    return format_docs(docs)\n",
    "\n",
    "# Agent will decide: \"Do I need to retrieve documents?\"\n",
    "```\n",
    "\n",
    "This is the foundation of **Agentic RAG** - retrieval controlled by an intelligent agent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 11: Summary\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. **Why Tools Matter**\n",
    "   - LLMs can't DO things without tools\n",
    "   - Tools extend agent capabilities\n",
    "   - Agents decide when to use tools\n",
    "\n",
    "2. **Creating Tools**\n",
    "   - Use `@tool` decorator\n",
    "   - Write clear docstrings (LLM reads them!)\n",
    "   - Include examples and error handling\n",
    "\n",
    "3. **Tool Integration**\n",
    "   - `bind_tools()` gives LLM awareness of tools\n",
    "   - OpenAI function calling enables structured tool calls\n",
    "   - ToolNode executes tools automatically\n",
    "\n",
    "4. **Conditional Routing**\n",
    "   - Check `tool_calls` to decide next step\n",
    "   - Graph can loop back to assistant after tools\n",
    "   - This enables iterative, multi-step reasoning\n",
    "\n",
    "5. **ReAct Pattern**\n",
    "   - **Reason:** Agent analyzes query\n",
    "   - **Act:** Agent calls appropriate tool\n",
    "   - **Observe:** Agent sees tool result\n",
    "   - **Respond:** Agent generates final answer\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Topic 3: Agentic RAG** ‚≠ê\n",
    "- Create a retrieval tool using Chroma vector store\n",
    "- Agent decides when to retrieve vs answer from knowledge\n",
    "- Build a complete agentic RAG system\n",
    "- The core concept of this module!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Other Practice Exercises\n",
    "\n",
    "1. **Create a new tool** that converts temperatures (Celsius ‚Üî Fahrenheit)\n",
    "2. **Test tool priority** - what happens if multiple tools could work?\n",
    "3. **Add error handling** - make a tool that sometimes fails and see how the agent handles it\n",
    "4. **Multi-tool query** - ask something that requires using TWO tools in sequence\n",
    "5. **Improve prompts** - modify the system prompt to change tool usage behavior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercises\n",
    "## Exercise 1: Build Your First Stateful Agent\n",
    "\n",
    "### Task\n",
    "Create an agent with three custom tools:\n",
    "1. **Weather tool:** Returns simulated weather for a given city\n",
    "2. **Dictionary tool:** Looks up word definitions (simulate with a small dict)\n",
    "3. **Web search tool:** Uses DuckDuckGo to search the web for information\n",
    "\n",
    "### Requirements\n",
    "1. Define tools using `@tool` decorator\n",
    "2. Bind tools to LLM\n",
    "3. Implement conditional routing (agent decides which tool to use)\n",
    "4. Handle cases where no tool is needed\n",
    "5. Install DuckDuckGo search: `pip install duckduckgo-search`\n",
    "6. Use `DDGS().text()` method for web searches\n",
    "\n",
    "### Example Queries\n",
    "- \"What's the weather in Lagos?\" ‚Üí Uses weather tool\n",
    "- \"Define the word 'ephemeral'\" ‚Üí Uses dictionary\n",
    "- \"Search for latest AI news\" ‚Üí Uses DuckDuckGo web search\n",
    "- \"What's the capital of France?\" ‚Üí No tool needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reflection Questions\n",
    "\n",
    "1. **How does the agent \"know\" which tool to use?**\n",
    "   \n",
    "2. **What role does the tool docstring play?**\n",
    "   \n",
    "3. **Why do we need conditional edges for tool-using agents?**\n",
    "   \n",
    "4. **What would happen if we didn't loop back to assistant after tools?**\n",
    "   \n",
    "5. **How is this different from just calling functions in regular Python code?**\n",
    "\n",
    "Think about these before moving to Topic 3!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "**üéâ Topic 2 Complete!**\n",
    "\n",
    "You now know how to build agents that use tools! Next: **Agentic RAG** - where retrieval becomes a tool that agents control!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n",
      "‚úÖ API key loaded\n",
      "‚úÖ LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Build Your First Stateful Agent\n",
    "# =============================================\n",
    "\n",
    "# 1. Install required packages (run once)\n",
    "# !pip install -q langgraph langchain langchain-openai duckduckgo-search python-dotenv\n",
    "\n",
    "import os\n",
    "from typing import Literal\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "print(\"‚úÖ All imports successful\")\n",
    "\n",
    "# Load environment variables (API keys)\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in .env file\")\n",
    "\n",
    "print(\"‚úÖ API key loaded\")\n",
    "\n",
    "# Initialize LLM (using a relatively small but capable model)\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "def safe_tool_execution(func):\n",
    "    \"\"\"Catch exceptions ‚Üí return friendly message instead of crash\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            tool_name = func.__name__\n",
    "            return (\n",
    "                f\"Error in tool '{tool_name}': {type(e).__name__}\\n\"\n",
    "                f\"Message: {str(e)}\\n\"\n",
    "                f\"Try again with correct input format.\"\n",
    "            )\n",
    "    return wrapper\n",
    "print(f\"‚úÖ LLM initialized: {llm.model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import ddgs python package. Please install it with `pip install -U ddgs`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\akind\\OneDrive\\Desktop\\Agentic files\\Agenvenv\\Lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:49\u001b[39m, in \u001b[36mDuckDuckGoSearchAPIWrapper.validate_environment\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mddgs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DDGS  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ddgs'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m means: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdefinitions[word]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Real web search tool\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m web_search = \u001b[43mDuckDuckGoSearchRun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úì All tools defined\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\akind\\OneDrive\\Desktop\\Agentic files\\Agenvenv\\Lib\\site-packages\\langchain_core\\tools\\base.py:541\u001b[39m, in \u001b[36mBaseTool.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    536\u001b[39m     msg = (\n\u001b[32m    537\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33margs_schema must be a subclass of pydantic BaseModel or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33ma JSON schema dict. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[33m'\u001b[39m\u001b[33margs_schema\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    539\u001b[39m     )\n\u001b[32m    540\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\akind\\OneDrive\\Desktop\\Agentic files\\Agenvenv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:117\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    116\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419  # Intentional blank docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 2 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\akind\\OneDrive\\Desktop\\Agentic files\\Agenvenv\\Lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:51\u001b[39m, in \u001b[36mDuckDuckGoSearchAPIWrapper.validate_environment\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mddgs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DDGS  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     52\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import ddgs python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     53\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install -U ddgs`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     54\u001b[39m     )\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[31mImportError\u001b[39m: Could not import ddgs python package. Please install it with `pip install -U ddgs`."
     ]
    }
   ],
   "source": [
    "# Tools\n",
    "\n",
    "\n",
    "@tool\n",
    "@safe_tool_execution\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Get current weather for a given city (simulated data).\n",
    "    Best for Nigerian cities.\n",
    "    \"\"\"\n",
    "    weather_data = {\n",
    "        \"lagos\": \"28¬∞C, partly cloudy, 78% humidity, feels like 31¬∞C\",\n",
    "        \"ibadan\": \"27¬∞C, mostly cloudy, 72% humidity\",\n",
    "        \"abuja\": \"26¬∞C, sunny intervals, 45% humidity\",\n",
    "        \"portharcourt\": \"29¬∞C, light rain, 90% humidity\",\n",
    "        \"kano\": \"24¬∞C, hazy and dry, 30% humidity\",\n",
    "    }\n",
    "    \n",
    "    city = city.lower().strip()\n",
    "    if not city:\n",
    "        raise ValueError(\"City name cannot be empty\")\n",
    "    \n",
    "    if city not in weather_data:\n",
    "        raise KeyError(f\"No weather data for '{city}'\")\n",
    "        \n",
    "    return f\"Current weather in {city.title()} (as of {datetime.now().strftime('%Y-%m-%d')}): {weather_data[city]}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "@safe_tool_execution\n",
    "def dictionary_lookup(word: str) -> str:\n",
    "    \"\"\"\n",
    "    Look up definition of common English words (small curated list).\n",
    "    \"\"\"\n",
    "    definitions = {\n",
    "        \"ephemeral\": \"lasting for a very short time\",\n",
    "        \"resilient\": \"able to withstand or recover quickly from difficult conditions\",\n",
    "        \"serendipity\": \"finding something good by happy accident\",\n",
    "        \"eloquent\": \"fluent or persuasive in speaking or writing\",\n",
    "        \"ubiquitous\": \"present or found everywhere\",\n",
    "    }\n",
    "    \n",
    "    word = word.lower().strip()\n",
    "    if not word:\n",
    "        raise ValueError(\"Word cannot be empty\")\n",
    "    \n",
    "    if word not in definitions:\n",
    "        raise KeyError(f\"'{word}' not found in dictionary\")\n",
    "        \n",
    "    return f\"'{word}' means: {definitions[word]}\"\n",
    "\n",
    "\n",
    "# Real web search tool\n",
    "web_search = DuckDuckGoSearchRun(name=\"web_search\")\n",
    "\n",
    "print(\"‚úì All tools defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Safe calculator tool created\n"
     ]
    }
   ],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "@tool\n",
    "def safe_calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Safely evaluate simple math expressions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Very restricted environment\n",
    "        result = eval(\n",
    "            expression,\n",
    "            {\"__builtins__\": {}},  # no built-ins\n",
    "            {}                     # no globals/locals\n",
    "        )\n",
    "        return str(result)\n",
    "        \n",
    "    except SyntaxError:\n",
    "        return \"Syntax error in expression. Example correct formats: 2+2, 15*3, 100/4\"\n",
    "    except NameError:\n",
    "        return \"Only numbers and basic operators (+ - * / ** // %) are allowed.\"\n",
    "    except ZeroDivisionError:\n",
    "        return \"Cannot divide by zero!\"\n",
    "    except Exception as e:\n",
    "        return f\"Calculation failed: {type(e).__name__} - {str(e)}\"\n",
    "print(\"‚úÖ Safe calculator tool created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'StructuredTool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# ‚îÄ‚îÄ‚îÄ Testing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mget_weather\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLagos\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     89\u001b[39m     \u001b[38;5;28mprint\u001b[39m(get_weather(\u001b[33m\"\u001b[39m\u001b[33mParis\u001b[39m\u001b[33m\"\u001b[39m))             \u001b[38;5;66;03m# ‚Üí error from decorator\u001b[39;00m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28mprint\u001b[39m(dictionary_lookup(\u001b[33m\"\u001b[39m\u001b[33mephemeral\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mTypeError\u001b[39m: 'StructuredTool' object is not callable"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "def safe_tool_execution(func):\n",
    "    \"\"\"\n",
    "    Catches exceptions from the original function and returns friendly error message.\n",
    "    Must be applied BEFORE @tool decorator.\n",
    "    \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            # We can still access the original function name safely here\n",
    "            tool_name = func.__name__\n",
    "            return (\n",
    "                f\"Error in tool '{tool_name}': {type(e).__name__}\\n\"\n",
    "                f\"Message: {str(e)}\\n\"\n",
    "                f\"Try again with correct input format.\"\n",
    "            )\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Correct decorator order ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "@tool\n",
    "@safe_tool_execution\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Get current weather for a given city (simulated data).\n",
    "    \n",
    "    Useful for questions like \"weather in Lagos\", \"how is the weather in Abuja\".\n",
    "    Only supports major Nigerian cities.\n",
    "    \"\"\"\n",
    "    weather_data = {\n",
    "        \"lagos\": \"28¬∞C, partly cloudy, 78% humidity, feels like 31¬∞C\",\n",
    "        \"abuja\": \"26¬∞C, sunny, 45% humidity, light breeze\",\n",
    "        \"ibadan\": \"27¬∞C, scattered clouds, 70% humidity\",\n",
    "    }\n",
    "    \n",
    "    city_clean = city.lower().strip()\n",
    "    if not city_clean:\n",
    "        raise ValueError(\"City name cannot be empty\")\n",
    "    if city_clean not in weather_data:\n",
    "        raise KeyError(f\"No weather data for '{city}'\")\n",
    "    \n",
    "    return f\"Current weather in {city.title()}: {weather_data[city_clean]}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "@safe_tool_execution\n",
    "def dictionary_lookup(word: str) -> str:\n",
    "    \"\"\"\n",
    "    Look up the definition of a common English word.\n",
    "    \"\"\"\n",
    "    definitions = {\n",
    "        \"ephemeral\": \"lasting for a very short time\",\n",
    "        \"resilient\": \"able to recover quickly\",\n",
    "    }\n",
    "    \n",
    "    word_clean = word.lower().strip()\n",
    "    if not word_clean:\n",
    "        raise ValueError(\"Word cannot be empty\")\n",
    "    if word_clean not in definitions:\n",
    "        raise KeyError(f\"'{word}' not found\")\n",
    "    \n",
    "    return f\"'{word}' means: {definitions[word_clean]}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "@safe_tool_execution\n",
    "def safe_calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Safely evaluate simple mathematical expressions.\n",
    "    Supports: + - * / ** // % ()\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        raise type(e)(f\"Invalid expression: {str(e)}\")\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Testing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(get_weather(\"Lagos\"))\n",
    "    print(get_weather(\"Paris\"))             # ‚Üí error from decorator\n",
    "    print(dictionary_lookup(\"ephemeral\"))\n",
    "    print(safe_calculator(\"2 ** 10\"))\n",
    "    print(safe_calculator(\"100 / 0\"))       # ‚Üí error from decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All imports successful\n",
      "‚úì API key loaded\n",
      "‚úì LLM initialized: gpt-4o-mini\n",
      "‚úì All tools defined\n",
      "‚úì Stateful agent ready!\n",
      "\n",
      "Testing the agent:\n",
      "\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "Question: What's the weather like in Ibadan today?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Answer:\n",
      "The weather in Ibadan today is 27¬∞C, mostly cloudy, with a humidity of 72%.\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "Question: What does 'resilient' mean?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Answer:\n",
      "The word \"resilient\" means able to withstand or recover quickly from difficult conditions.\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "Question: What's the latest news about artificial intelligence?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Answer:\n",
      "The latest news about artificial intelligence includes updates on breakthroughs, technology trends, regulation, and ethical issues. Recent articles cover advancements in AI and machine learning, as well as discussions on the impact of AI on businesses and society. For more detailed articles, you can explore platforms like Reuters and Google News.\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n",
      "\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "Question: What's the capital city of Nigeria?\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Answer:\n",
      "The capital city of Nigeria is Abuja.\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Exercise 1: Build Your First Stateful Agent\n",
    "# Complete working version with error handling\n",
    "# Date: January 2026\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# 1. Install required packages (run this once if needed)\n",
    "# !pip install -q langgraph langchain langchain-openai langchain-community duckduckgo-search python-dotenv\n",
    "\n",
    "# 2. Imports\n",
    "import os\n",
    "from typing import Literal\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from functools import wraps\n",
    "\n",
    "print(\"‚úì All imports successful\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Load OpenAI API key\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in .env file\")\n",
    "\n",
    "print(\"‚úì API key loaded\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Initialize LLM\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "print(f\"‚úì LLM initialized: {llm.model_name}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Safe execution decorator (must come BEFORE @tool)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def safe_tool_execution(func):\n",
    "    \"\"\"Catch exceptions ‚Üí return friendly message instead of crash\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            tool_name = func.__name__\n",
    "            return (\n",
    "                f\"Error in tool '{tool_name}': {type(e).__name__}\\n\"\n",
    "                f\"Message: {str(e)}\\n\"\n",
    "                f\"Try again with correct input format.\"\n",
    "            )\n",
    "    return wrapper\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Tools\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "@tool\n",
    "@safe_tool_execution\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Get current weather for a given city (simulated data).\n",
    "    Best for Nigerian cities.\n",
    "    \"\"\"\n",
    "    weather_data = {\n",
    "        \"lagos\": \"28¬∞C, partly cloudy, 78% humidity, feels like 31¬∞C\",\n",
    "        \"ibadan\": \"27¬∞C, mostly cloudy, 72% humidity\",\n",
    "        \"abuja\": \"26¬∞C, sunny intervals, 45% humidity\",\n",
    "        \"portharcourt\": \"29¬∞C, light rain, 90% humidity\",\n",
    "        \"kano\": \"24¬∞C, hazy and dry, 30% humidity\",\n",
    "    }\n",
    "    \n",
    "    city = city.lower().strip()\n",
    "    if not city:\n",
    "        raise ValueError(\"City name cannot be empty\")\n",
    "    \n",
    "    if city not in weather_data:\n",
    "        raise KeyError(f\"No weather data for '{city}'\")\n",
    "        \n",
    "    return f\"Current weather in {city.title()} (as of {datetime.now().strftime('%Y-%m-%d')}): {weather_data[city]}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "@safe_tool_execution\n",
    "def dictionary_lookup(word: str) -> str:\n",
    "    \"\"\"\n",
    "    Look up definition of common English words (small curated list).\n",
    "    \"\"\"\n",
    "    definitions = {\n",
    "        \"ephemeral\": \"lasting for a very short time\",\n",
    "        \"resilient\": \"able to withstand or recover quickly from difficult conditions\",\n",
    "        \"serendipity\": \"finding something good by happy accident\",\n",
    "        \"eloquent\": \"fluent or persuasive in speaking or writing\",\n",
    "        \"ubiquitous\": \"present or found everywhere\",\n",
    "    }\n",
    "    \n",
    "    word = word.lower().strip()\n",
    "    if not word:\n",
    "        raise ValueError(\"Word cannot be empty\")\n",
    "    \n",
    "    if word not in definitions:\n",
    "        raise KeyError(f\"'{word}' not found in dictionary\")\n",
    "        \n",
    "    return f\"'{word}' means: {definitions[word]}\"\n",
    "\n",
    "\n",
    "# Real web search tool\n",
    "web_search = DuckDuckGoSearchRun(name=\"web_search\")\n",
    "\n",
    "print(\"‚úì All tools defined\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Combine tools & bind to LLM\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "tools = [get_weather, dictionary_lookup, web_search]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful assistant with 3 tools:\n",
    "\n",
    "1. get_weather     ‚Üí Nigerian city weather (simulated)\n",
    "2. dictionary_lookup ‚Üí English word definitions\n",
    "3. web_search      ‚Üí current events, facts, general knowledge\n",
    "\n",
    "Rules:\n",
    "- Use get_weather for weather questions about Nigerian cities\n",
    "- Use dictionary_lookup for word meanings\n",
    "- Use web_search for news, history, or anything else\n",
    "- If you know the answer confidently, answer directly\n",
    "- Be concise, polite and helpful\n",
    "\"\"\"\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# LangGraph Agent Setup\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"]\n",
    "    return {\"messages\": [llm_with_tools.invoke(messages)]}\n",
    "\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    if last_msg.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "\n",
    "# Build graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"assistant\", assistant)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "workflow.add_edge(START, \"assistant\")\n",
    "workflow.add_conditional_edges(\"assistant\", should_continue)\n",
    "workflow.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# Memory\n",
    "memory = MemorySaver()\n",
    "agent = workflow.compile(checkpointer=memory)\n",
    "\n",
    "print(\"‚úì Stateful agent ready!\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Interactive testing function\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def ask(question: str, thread_id=\"conversation_1\"):\n",
    "    \"\"\"Ask the agent a question and show the answer + tool usage\"\"\"\n",
    "    print(f\"\\n{'‚ïê'*70}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"{'‚îÄ'*70}\")\n",
    "    \n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=question)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    \n",
    "    final_msg = result[\"messages\"][-1]\n",
    "    print(\"Answer:\")\n",
    "    print(final_msg.content)\n",
    "    \n",
    "    if hasattr(final_msg, \"tool_calls\") and final_msg.tool_calls:\n",
    "        print(\"\\nTools used:\")\n",
    "        for tc in final_msg.tool_calls:\n",
    "            print(f\" ‚Ä¢ {tc['name']} ‚Üí {tc['args']}\")\n",
    "    \n",
    "    print(\"‚ïê\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Run some example questions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nTesting the agent:\\n\")\n",
    "    \n",
    "    ask(\"What's the weather like in Ibadan today?\")\n",
    "    ask(\"What does 'resilient' mean?\")\n",
    "    ask(\"What's the latest news about artificial intelligence?\")\n",
    "    ask(\"What's the capital city of Nigeria?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agenvenv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
